{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This section investigates patterns and relationships among the vessels that did not appear in the IMO database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "| Column | Datatype | Description |\n",
    "|---------------------------|----------|-------------------------------------------------------------------------------------------------------|\n",
    "| ssvid | int64 | the vessel's MMSI code which is it's \"unique\" AIS ID |\n",
    "| gap_hours | float64 | length of the gap event |\n",
    "| gap_distance_m | float64 | distance of the gap event in miles |\n",
    "| gap_implied_speed_knots | float64 |  |\n",
    "| positions_per_day | float64 |  |\n",
    "| vessel_class | object | vessel geartype |\n",
    "| flag | object | The state a vessel is registered or licensed under |\n",
    "| off_timestamp | object | timestamp AIS was turned off |\n",
    "| off_msgid | object | message ID from AIS turning off |\n",
    "| off_lat | float64 | latitude when AIS turned off |\n",
    "| off_lon | float64 | longitude when AIS turned off |\n",
    "| off_type | object | the class of AIS device (A or B), Class A devices are more expensive, have stronger signals and broadcast more frequently |\n",
    "| off_receiver_type | object | whether the AIS message was recieved by a satellite or terrestrial receiver when turned off |\n",
    "| off_distance_from_shore_m | float64 | distance from shore when AIS turned off |\n",
    "| on_timestamp | object | timestamp AIS was turned on |\n",
    "| on_msgid | object | message ID from AIS turning on |\n",
    "| on_lat | float64 | latitude when AIS turned on |\n",
    "| on_lon | float64 | longitude when AIS turned on |\n",
    "| on_type | object | the class of AIS device (A or B), class A devices have stronger signals and broadcast more frequently |\n",
    "| on_receiver_type | object | whether the AIS message was recieved by a satellite or terrestrial receiver when turned on |\n",
    "| on_distance_from_shore_m | float64 | distance from shore when AIS turned on |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Clustering models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IMO non registered list and gap events dataset\n",
    "imo_notreg = pd.read_csv('./data/imo_notreg.csv')\n",
    "gap_events = pd.read_csv('./data/raw_sample.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the contents\n",
    "print(f'Total Non-Registered Vessels: {len(imo_notreg)}')\n",
    "print(f'Gap Events: {len(gap_events)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imo_notreg['0'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Confirm highest number of times a vessel appears\n",
    "imo_notreg['0'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Clean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the full gap events dataset to only include the non registered vessels\n",
    "gap_notreg = gap_events[gap_events['ssvid'].isin(imo_notreg['0'])]\n",
    "gap_notreg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ssvid column name for consistency\n",
    "gap_notreg = gap_notreg.rename(columns={'ssvid':'mmsi'})\n",
    "gap_notreg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_notreg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which countries have the most gap events?\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "countries = sns.countplot(x=\"flag\", data=gap_notreg, palette=\"Set3\",\n",
    "              order=gap_notreg['flag'].value_counts().iloc[:20].index).set(xlabel='Country',\n",
    "                                                                           ylabel='Observations',\n",
    "                                                                           title='Count of Gap Events by Country (top 20)');\n",
    "\n",
    "# for bar in countries.patches:\n",
    "#     countries.annotat(format(bar.get_height(), '.2f'), \n",
    "#                       (p.get_x() + p.get_width() / 2., \n",
    "#                        p.get_height()), \n",
    "#                        ha = 'center',  \n",
    "#                        va = 'center', \n",
    "#                        xytext = (0, 10), \n",
    "#                        textcoords = 'offset points')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = gap_notreg.duplicated()\n",
    "gap_notreg[duplicates].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "gap_notreg = gap_notreg.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change time columns to datetime\n",
    "gap_notreg['off_timestamp'] = pd.to_datetime(gap_notreg['off_timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "gap_notreg['on_timestamp'] = pd.to_datetime(gap_notreg['on_timestamp'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check timeframe\n",
    "gap_notreg['off_timestamp'].min(), gap_notreg['off_timestamp'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Model: Clustering Length of Gap Event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to looking at a vessel's location at the point of going dark, it's worth taking into account the length of the gap event. This DBSCAN model also takes in the gap_hours variable. Increasing the number of variables proved to be very computationally expensive, so I use principle component analysis for dimensionality reduction.\n",
    "\n",
    "\n",
    "|  eps  | min_samples | number of clusters | PCA |\n",
    "|:-----:|:-----------:|:------------------:|:---:|\n",
    "|  0.05 |      40     |         66         |  Y  |\n",
    "|  0.05 |      40     |         66         |  N  |\n",
    "| 0.001 |      40     |         294        |  Y  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20 / 6371.0088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of only lat/lon/gap_hr data\n",
    "X = gap_notreg[['off_lat', 'off_lon', 'gap_hours']]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "ss = StandardScaler()\n",
    "X_sc = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components= X_sc.shape[1])\n",
    "X_pca = pca.fit_transform(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit principle components\n",
    "dbscan = DBSCAN(eps=0.05, min_samples= 40, metric='euclidean')\n",
    "dbscan.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit\n",
    "dbscan = DBSCAN(eps=.05, min_samples= 40, metric='euclidean')\n",
    "dbscan.fit(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many clusters were created\n",
    "# len(set(dbscan.labels_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the silhouette score\n",
    "# silhouette_score(off_coords, dbscan.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Model: Clustering Coordinates Where Vessels Go Dark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The popular clustering algorithm DBSCAN is a useful tool for exploration at this stage because it creates clusters by linking nearby data points to one another. I will feed in the location data at the moment vessels go dark (turn off their AIS transponders).\n",
    "\n",
    "The latitude and longitude coordinates must be [converted from degrees to radians](https://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size/) in order to use Scikit-Learn's haversine distance metric. The algorithm uses an epsilon value (distance threshold) of 20 km, which is also converted to radian units. Min samples are set at 40 as it seemed reasonable to assume that 40 instances of a vessel going dark within a 20 km radius is indicative of suspicious behavior. Scaling is not required since the data is in latitude longitude coordinates. **Add comment on ball tree algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Latitude and Longitude Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a dataframe of only lat/lon at AIS switch off\n",
    "\n",
    "latlon_off = gap_notreg[['off_lat', 'off_lon']]\n",
    "latlon_on = gap_notreg[['on_lat', 'on_lon']]\n",
    "\n",
    "latlon_off.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latlon_on.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to numpy matrices\n",
    "off_coords = latlon_off.to_numpy()\n",
    "on_coords = latlon_on.to_numpy()\n",
    "\n",
    "# check array\n",
    "off_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert epsilon and coordinates to radians \n",
    "# code adapted from Geoff Boeing\n",
    "kms_per_radian = 6371.0088\n",
    "epsilon = 20 / kms_per_radian \n",
    "\n",
    "off_coords = np.radians(off_coords)\n",
    "on_coords = np.radians(on_coords)\n",
    "\n",
    "# check array\n",
    "off_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and fit\n",
    "dbscan = DBSCAN(eps=epsilon, min_samples= 40, algorithm='ball_tree', metric='haversine')\n",
    "dbscan.fit(off_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many clusters were created\n",
    "len(set(dbscan.labels_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in data and clusters to get the silhouette score\n",
    "#silhouette_score(off_coords, dbscan.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster column\n",
    "latlon_off['off_cluster'] = dbscan.labels_\n",
    "latlon_off.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which clusters have the most observations?\n",
    "latlon_off['off_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(latlon_off['off_lat'], latlon_off['off_lon'], c=dbscan.labels_, s=1, cmap=\"tab20\")\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Longitude')\n",
    "plt.title('Location of Vessel at AIS Off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break top 3 clusters into dataframes and visualize (including noise)\n",
    "\n",
    "cluster0 = latlon_off[latlon_off['off_cluster'] == 0]\n",
    "cluster_1 = latlon_off[latlon_off['off_cluster'] == -1]\n",
    "cluster11 = latlon_off[latlon_off['off_cluster'] == 11]\n",
    "cluster18 = latlon_off[latlon_off['off_cluster'] == 18]\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.scatter(cluster0['off_lat'], cluster0['off_lon'], s=1, c='skyblue');\n",
    "plt.scatter(cluster_1['off_lat'], cluster_1['off_lon'], s=1, c='lavender');\n",
    "plt.scatter(cluster11['off_lat'], cluster11['off_lon'], s=1, c='b')\n",
    "plt.scatter(cluster18['off_lat'], cluster18['off_lon'], s=1, c='gold')\n",
    "plt.title('Largest Clusters: Location at AIS Off')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Longitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Predictions to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cluster into the original dataframe\n",
    "gap_notreg = gap_notreg.merge(latlon_off, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# Drop the additional lat/lon columns\n",
    "gap_notreg.drop(columns=['off_lat_y', 'off_lon_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "gap_notreg.rename(columns={'off_lat_x' : 'off_lat',\n",
    "                           'off_lon_x' : 'off_lon'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated dataframe to CSV\n",
    "gap_notreg.to_csv('./data/gap_notreg.csv', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore any patterns in the first few clusters\n",
    "gap_notreg.groupby('off_cluster')[['gap_hours', \n",
    "                                   'gap_distance_m',\n",
    "                                   'positions_per_day', \n",
    "                                   'on_distance_from_shore_m',\n",
    "                                   'off_distance_from_shore_m',]].mean().T.loc[:,[0,11,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break into individual dataframes\n",
    "cluster0 = gap_notreg[gap_notreg['off_cluster'] == 0]\n",
    "cluster11 = gap_notreg[gap_notreg['off_cluster'] == 11]\n",
    "cluster18 = gap_notreg[gap_notreg['off_cluster'] == 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on Location Clusters\n",
    "\n",
    "- Total Observations: 208,866\n",
    "- Unique Vessels (MMSI): 30,297\n",
    "- Avg Length of Gaps: 148.70 hrs\n",
    "- Avg Num Positions per Day: 9.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Which vessel classes appear the most in cluster 0 and how often?\n",
    "\n",
    "plt.figure(figsize=(12,9)) \n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.countplot(y=\"vessel_class\", \n",
    "              data=cluster0, \n",
    "              palette=\"icefire_r\",\n",
    "              order=cluster0['vessel_class'].value_counts().iloc[:10].index).set(title=('Cluster 0 Vessel Classes'),\n",
    "                                                                                 xlabel=('Vessel Count'),\n",
    "                                                                                 ylabel=('Gear Type'))\n",
    "plt.subplot(2,2,2)\n",
    "sns.countplot(y=\"vessel_class\", \n",
    "              data=cluster11, \n",
    "              palette=\"icefire_r\",\n",
    "              order=cluster11['vessel_class'].value_counts().iloc[:10].index).set(title=('Cluster 11 Vessel Classes'),\n",
    "                                                                                 xlabel=('Vessel Count'),\n",
    "                                                                                 ylabel=('Gear Type'))\n",
    "plt.subplot(2,2,3)\n",
    "sns.countplot(y=\"vessel_class\", \n",
    "              data=cluster18, \n",
    "              palette=\"icefire_r\",\n",
    "              order=cluster18['vessel_class'].value_counts().iloc[:10].index).set(title=('Cluster 18 Vessel Classes'),\n",
    "                                                                                 xlabel=('Vessel Count'),\n",
    "                                                                                 ylabel=('Gear Type'))\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average gap hours for the vessels classes that appear the most?\n",
    "\n",
    "cluster0.loc[cluster0['vessel_class'] == 'trawlers']['gap_hours'].mean()\n",
    "cluster0[(cluster0['vessel_class'] == 'trawlers')]['gap_hours'].mean()\n",
    "\n",
    "cluster11[(cluster11['vessel_class'] == 'set_longlines')]['gap_hours'].mean()\n",
    "\n",
    "cluster18[(cluster18['vessel_class'] == 'set_longlines')]['gap_hours'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average number of positions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which countries have the highest average gaps\n",
    "cluster0.groupby('flag')['gap_hours'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which vessels have the highest avg gaps and where are they from?\n",
    "cluster0.groupby(['mmsi','flag','vessel_class'])['gap_hours'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any relationships between location and the length of the gap event?\n",
    "# Within cluster 0 zoom in on the gaps lasting less 1000 hours\n",
    "\n",
    "def gaps_scatter(cluster):\n",
    "    low_gaps = cluster[cluster['gap_hours'] < 1000]\n",
    "    return low_gaps.plot(kind=\"scatter\", \n",
    "                  x=\"off_lat\",\n",
    "                  y=\"off_lon\", \n",
    "                  c=\"gap_hours\",\n",
    "                  cmap=\"icefire_r\", \n",
    "                  figsize=(14, 10), \n",
    "                  s=4, \n",
    "                  title='Length of Gap Events by Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_scatter(cluster0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_scatter(cluster11);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_scatter(cluster18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When did the highest number of gap events take place?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of gap hours\n",
    "\n",
    "# high_gaps = gap_notreg[gap_notreg['gap_hours'] > 2000]\n",
    "# low_gaps = gap_notreg[gap_notreg['gap_hours'] < 2000]\n",
    "\n",
    "# plt.figure(figsize=(18,6))\n",
    "# sns.distplot(low_gaps['gap_hours']).set(xlabel='Number of Hours off Radar', \n",
    "#                                         ylabel='Number of Vessels', \n",
    "#                                         title='Gap Hr Distribution (Under 2000 hrs)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "gap_notreg.to_csv('./data/gap_notreg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size/\n",
    "- https://link.springer.com/chapter/10.1007/978-3-030-38081-6_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174.347px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
